[{"content":"本人通过 Obsidian + Hugo + Github Page + Github Action 来实现文章管理及博客自动化搭建.\nHugo 渲染白名单 因为不想将 Obsidian 仓库中的一些隐私笔记发布到博客上, 于是选择使用 module.mounts 来配置允许 Hugo 渲染的文件夹.\n1module: 2 mounts: 3 - source: \u0026#34;content/posts/3. Resources-资源 未来/AI人工智能\u0026#34; 4 target: \u0026#34;content/posts/AI人工智能\u0026#34; 5 - source: \u0026#34;content/posts/4. Archives-归档/技术类归档\u0026#34; 6 target: \u0026#34;content/posts/技术类归档\u0026#34; 7\t...... 8 - source: \u0026#34;content/about.md\u0026#34; 9 target: \u0026#34;content/about.md\u0026#34; 10\t...... Hugo 主页展示白名单 因为主要想在博客主页展示技术类相关博文, 所以需要对主页展示内容进行过滤, 在 layouts/_default/list.html 进行配置即可, 具体可参考下面的代码:\n1{{- if .IsHome }} 2{{- $pages = where site.RegularPages \u0026#34;File.Dir\u0026#34; \u0026#34;in\u0026#34; (slice \u0026#34;posts\\\\AI人工智能\\\\\u0026#34; \u0026#34;posts\\\\技术类归档\\\\\u0026#34;) }} 3{{- $pages = where $pages \u0026#34;Params.hiddenInHomeList\u0026#34; \u0026#34;!=\u0026#34; \u0026#34;true\u0026#34; }} 4{{- end }} 倘若不知道文件夹(File. Dir)路径, 尤其是我这种有 mounts 映射的情况, 可以通过在 layouts/_default/list.html 中添加 {{ range site.RegularPages }} \u0026lt;p\u0026gt;{{ .File.Path }} → {{ .File.Dir }}\u0026lt;/p\u0026gt; {{ end }} 代码块, Hugo 会输出文件夹 (File. Dir) 路径 (类似 Python 的 print 函数.), 见下图:\n踩坑记录: 一开始以为在 config.yml 里面设置 mainSections 相关参数即可, 折腾半天. 后面静下心来慢慢读 Hugo 的官网网站上的相关教程, 最后也多亏了 GPT 帮忙.\n上传 Github 白名单 可通过 .gitignore 文件进行设置.\n1 2content/posts/.obsidian/ # .obsidian文件夹内里面有很多杂七杂八的东西 3content/posts/-1. Books/ # 这一目录用于存放电子书, 占用空间 4 5.history/ # VSC的自动保存 6 7public # 无需上传public文件, 因为设置了Github Action自动部署 这个网上很多大佬都有教程 ","permalink":"https://iceyorange.github.io/posts/%E6%8A%80%E6%9C%AF%E7%B1%BB%E5%BD%92%E6%A1%A3/hugo-%E6%B8%B2%E6%9F%93%E5%8F%8A%E4%B8%BB%E9%A1%B5%E5%B1%95%E7%A4%BA%E7%99%BD%E5%90%8D%E5%8D%95/","summary":"本人通过 Obsidian + Hugo + Github Page + Github Action 来实现文章管理及博客自动化搭建. Hugo 渲染白名单 因为不想将 Obsidian 仓库中的一些隐私笔记发布到博客上, 于是选择使用 module.mounts 来配置允许 Hugo 渲染的文件夹. 1module: 2 mounts: 3 - source: \u0026#34;content/posts/3. Resources-资源 未来/AI人工智能\u0026#34; 4 target: \u0026#34;content/posts/AI人工智能\u0026#","title":"Hugo 渲染及主页展示白名单"},{"content":"记得在看《被讨厌的勇气》后，里面有一句话让我印象特别深刻：“影响你的不是事件本身，而是你==看待事件的方式==。”比如精神内耗与否，就与==如何看待事情==息息相关[[关于精神内耗#内耗和复盘]]。再比如经验不是事情本身, 是我们理解事情的方式, 构成了经验。但是需要注意的是，==不要脱离或弱化了“物质的决定性”==。\n","permalink":"https://iceyorange.github.io/posts/%E9%9A%8F%E7%AC%94/%E5%85%B3%E4%BA%8E%E4%B8%BB%E8%A7%82%E8%83%BD%E5%8A%A8%E6%80%A7/","summary":"记得在看《被讨厌的勇气》后，里面有一句话让我印象特别深刻：“影响你的不是事件本身，而是你==看待事件的方式==。”比如精神内耗与否，就与==如何看待事情==息息相关[[关于精神内耗#内耗和复盘]]。再比如经验不是事情本身, 是我们理解事情的方式, 构成了经验。但是需要注意的是，==不","title":"关于主观能动性"},{"content":" 如果你因为失去了太阳而流泪，那么你也将失去群星。 - 泰戈尔\n什么是精神内耗 精神内耗表现为个体对未知不确定事件可能的消极原因或后果进行反复的揣摩、思考与分析。 - 百度百科\n心理内耗是指人的自我控制需要消耗心理资源，当资源不足时，个体即处于一种所谓内耗的状态，长期的内耗会让人感到疲惫。 - MBA智库\n内耗和复盘 精神内耗 Vs 真正的复盘，他们之间区别在于：==精神内耗==是过度的无用思考，不断地==反刍==：“我当时为什么要这样做”；==真正的复盘==，虽然也会分析当时做错事的原因，但其重点是：以后==怎么做==以避免再犯类似的错误。 ^ah26bl\n如何应对精神内耗 不要试图去压制自己的反刍思维，这样反而可能会因为白熊效应让负面思考变得更加频繁，这可能会形成恶性循环。\n白熊效应，又称白象效应或反弹效应：刻意抑制某些想法时，实际上会使这些想法更容易浮出水面。一个例子是，当某人积极地试图不去想一只白熊时，他实际上更有可能想象一只白熊。 - Wikipedia\n具体怎么做：\n自我接纳（只要你完成了今天的目标，你就问心无愧。其它的事，无需今日承担。 - 小红书评论） 旁观视角（分清情绪和问题） 积极行动（行动是治愈反刍的良药） 有意识地转移注意力（如正念冥想、心理干预）等等 ","permalink":"https://iceyorange.github.io/posts/%E9%9A%8F%E7%AC%94/%E5%85%B3%E4%BA%8E%E7%B2%BE%E7%A5%9E%E5%86%85%E8%80%97/","summary":"如果你因为失去了太阳而流泪，那么你也将失去群星。 - 泰戈尔 什么是精神内耗 精神内耗表现为个体对未知不确定事件可能的消极原因或后果进行反复的揣摩、思考与分析。 - 百度百科 心理内耗是指人的自我控制需要消耗心理资源，当资源不足时，个体即处于一种所谓内耗的状态，长期的内耗会让人感到疲惫。 - MB","title":"关于精神内耗"},{"content":"\u0026ldquo;矛盾\u0026quot;的意思即\u0026quot;两面性\u0026rdquo;(道家的\u0026quot;阴阳\u0026quot;)?\n思考的两面性 - 人类认知边界 × 语言符号系统 思考的正面性，或者通俗来说，思考的优点，是显而易见的。\n下面主要来说说==思考的反面性==：\n语言的界限就是世界的界限。 - 《维特根斯坦与哲学》 知乎的一个解读 没有语言，人类就无法思考。 - 索绪尔 知乎对索绪尔或语言学的一个介绍 道可道，非常（恒）道。 - 老子《道德经》\n结构主义认为语言的结构决定了我们的思维模式。\n深入了解一下结构主义, 索绪尔, 列维斯特劳斯 #哲学 我们只能想到我们能够想到的东西（意象无法表达）, 或者说，我们只能表达出语言能够表达出地东西，只能思考『能够被语言表达』的东西。语言之外的东西，我们无法思考。就好比盲人无法思考光明、聋人无法思考声音、人类无法思考高维空间（“上帝面前，我们都是聋子”）\n人类在认知进程中不断重构\u0026quot;可言说\u0026quot;与\u0026quot;不可言说\u0026quot;的边界形态，例如随着阅历或认知的进长，我们渐渐能够表达从前无法用语言表达的想法或观点，但是，这个边界本身是永远不能被消除的。\n《庄子·内篇·养生主第三》中的哲思：\u0026ldquo;吾生也有涯，而知也无涯。以有涯随无涯，殆已！\u0026quot;，人类的伟大恰在于明知\u0026quot;殆\u0026quot;而仍不懈追寻。\nDDL 的双面性 设计应该是感性的还是理性的？设计是感性重要还是理性重要？ 此类问题一经出现便会引起争议无数，每个人对此都有自己的见解与理由，还有些人主张“理性与感性需要平衡”“既要理性也要感性”，==此类观点看似正确，却缺乏任何实质性的指导价值==。 - 设计的两面性：理性决策与感性表达\n马哲所谓的\u0026quot;辩证分析法\u0026rdquo;, 听上去似乎正确, 但实际上, 就像上面引用的文章所提到的: 缺乏实质性的指导价值.\n","permalink":"https://iceyorange.github.io/posts/%E9%9A%8F%E7%AC%94/%E5%85%B3%E4%BA%8E%E9%A9%AC%E5%93%B2%E4%B8%AD%E7%9F%9B%E7%9B%BE%E4%B8%8E%E9%98%B4%E9%98%B3/","summary":"\u0026ldquo;矛盾\u0026quot;的意思即\u0026quot;两面性\u0026rdquo;(道家的\u0026quot;阴阳\u0026quot;)? 思考的两面性 - 人类认知边界 × 语言符号系统 思考的正面性，或者通俗来说，思考的优点，是显而易见的。 下面主要来说说==思考的反面性==： 语言的界限就是世界的界限。 - 《维特根斯坦","title":"关于马哲中矛盾与阴阳"},{"content":"人会借势是强者的表现\n思虑过多的人, 应该去多感受大千世界.\n一件事情, 明知道没有希望, 却在尘埃落定之前, 一直抱有希望. 就像宣判死刑前心怀侥幸的十恶不赦的罪犯.\n","permalink":"https://iceyorange.github.io/posts/%E9%9A%8F%E7%AC%94/%E5%85%B6%E5%AE%83/","summary":"人会借势是强者的表现 思虑过多的人, 应该去多感受大千世界. 一件事情, 明知道没有希望, 却在尘埃落定之前, 一直抱有希望. 就像宣判死刑前心怀侥幸的十恶不赦的罪犯.","title":"其它"},{"content":"《湖南农民运动考察报告》 矫枉必须过正, 不过正不能矫枉.\n政权、族权、神权、夫权这四种权利代表了全部封建宗法的思想与制度.\n引而不发，跃如也。 - 农民的使命要农民去完成, 别人代庖是不对的\n《井冈山的斗争》 民主主义: 官长不打士兵, 官兵待遇平等, 士兵有开会说话的自由, 废除繁琐的礼节, 经济公开.\n家族主义: 一个村子一个姓, 支部会议简直同时就是家族会议.\n群众的政治训练 - 群众需要有政治素养\n党与政府的关系\n民权主义革命 - 民权主义是三民主义之一.\n《关于纠正党内的错误思想》 ==本位主义==, 一切只知道为四军打仗, 不知道武装地方群众是红军的重要任务之一. 这是一种放大了的小团体主义.\n俘虏兵的加入, 带来了浓厚的雇佣军队的思想, 使单纯军事观点有了==下层基础==.\n过分相信军事力量, 而不相信人民群众的力量.\n党对军事工作没有积极的注意和讨论, 也是形成一部分同志的单纯军事观点的原因.\n==关于极端民主化==, 『由下而上的民主集权制』, 『先交下级讨论, 再交上级决议』?\n有争论的问题, 要把是非弄明白, 不要调和敷衍.\n党内批评, 不要成了攻击个人.\n绝对平均主义的来源, 和政治上的极端民主化一样, 是手工业者和小农经济的产物, 不过一则见之于政治方面, 一则见之于物质生活方面罢了.\n看这篇文章有看加缪的《堕落》的感觉，被作者当面揭露出劣根性的感觉。原来自己曾经有过的许多想法，其实都有一个专有名词（如 xx 主义），一下抓住事情的本质并提炼成文字，伟人果然是伟人。\n","permalink":"https://iceyorange.github.io/posts/%E9%98%85%E8%AF%BB/%E6%AF%9B%E9%80%89%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/","summary":"《湖南农民运动考察报告》 矫枉必须过正, 不过正不能矫枉. 政权、族权、神权、夫权这四种权利代表了全部封建宗法的思想与制度. 引而不发，跃如也。 - 农民的使命要农民去完成, 别人代庖是不对的 《井冈山的斗争》 民主主义: 官长不打士兵, 官兵待遇平等, 士兵有开会说话的自由, 废除繁琐的礼节, 经济公开.","title":"毛选读书笔记"},{"content":"本地部署都很吃配置\n知识库 KB 知识库（Knowledge base）是用于知识管理的一种==特殊的数据库==，以便于有关领域知识的采集、整理以及提取。知识库中的知识源于领域专家，它是求解问题所需领域知识的集合，包括基本事实、规则和其它有关信息。 - Wikipedia\n例如：法院判例库、医院病例库、产品数据库、某领域论文库、哈利波特魔咒库、章鱼哥的食谱……\n注意！知识库与 LLM 预训练语料库两者不是一个概念，预训练语料库为非结构化文本（乱七八糟的文字, 未清洗）, 且一旦模型预训练完成就不能再更改预训练语料 (如ChatGPT 4o的预训练语料库便截止2023年10月); 而知识库则为结构化或半结构化文本 (有一级标题、二级标题或其他逻辑结构)，且是定期更新与维护的。\n看到很多人推荐 IMA 来搭建知识库.\n智能体 Agent 智能体（英语：intelligent agent）指一个可以==观察周遭环境并作出行动以达致目标==的自主实体。它通常是指（但不一定是）一个软件程序。“智能体”是目前人工智能研究的一个核心概念，统御和联系着各个子领域的研究。 - Wikipedia\n智能体（Agent）是指能够==感知环境并采取行动以实现特定目标==的代理体。它可以是软件、硬件或一个系统，具备自主性、适应性和交互能力。智能体通过感知环境中的变化（如通过传感器或数据输入），根据自身学习到的知识和算法进行判断和决策，进而执行动作以影响环境或达到预定的目标。 - 百度百科\n常见 AI Agent 平台: 字节扣子 (Coze)、腾讯元器、Dify、FastGPT\n所有妄图通过缩短工序而提升效率的低代码平台都会死. (Agent 平台就是 LLM 时代的低代码平台) - 小红书评论\n检索增强生成 RAG Retrieval-Augmented Generation (RAG) is the process of optimizing the output of a large language model, so ==it references an authoritative knowledge base outside of its training data sources before generating a response.== Large Language Models (LLMs) are trained on vast volumes of data and use billions of parameters to generate original output for tasks like answering questions, translating languages, and completing sentences. ==RAG extends the already powerful capabilities of LLMs to specific domains or an organization\u0026rsquo;s internal knowledge base, all without the need to retrain the model.== It is a cost-effective approach to improving LLM output so it remains relevant, accurate, and useful in various contexts. - AWS\n==检索增强生成==（英语：Retrieval-augmented generation, RAG ) 是赋予生成式人工智能模型信息检索能力的技术。检索增强生成优化大型语言模型(LLM) 的交互方式，让模型根据指定的一组文件回应用户的查询，并使用这些信息增强模型从自身庞大的静态训练数据中提取的信息。检索增强生成技术促使大型语言模型能够使用特定领域或更新后的信息。 - Wikipedia\n可以将RAG理解为\u0026quot;知识库+LLM\u0026quot;, \u0026ldquo;==AI 老员工==\u0026ldquo;的比喻十分形象。\n主流 RAG 框架: LangChain、RAGFlow、AnythingLLM\nRAG 具体工作逻辑 参考 Why does the LLM not use my documents?\nRAG 对知识库中的文件，并不是以一个文档一个文档地对待的，而是将所有文档都“打碎”并进行词嵌入； 当用户发起对话时，也将用户发送的对话内容“打碎”并进行词嵌入； 通过余弦相似度从知识库中寻找与用户发送内容“相似”的“碎片”。 整合 LLM，最后输出 RAG (which is what we use) enables us to chunk the document and then ask retrieve only the bits and pieces the make sense for your question and use that in the context window. This makes larger documents easier to use, but it is at the expense of these types of \u0026ldquo;whole document\u0026rdquo; understandings.- AnythingLLM 社区 RAG, by its very nature is pieces of relevant content. Not the entire text - AnythingLLM 社区\n总结：RAG 的作用不是全文理解，而是从知识库找到与我们所问的问题相关的“碎片”。至于全文理解，这件事是智能体干的事情，当然 LLM 也干得不错。为什么不本地部署一个强悍的 LLM ? 可以参考这里[[#总结]].\n微调 Fine-tuning 微调（又称大模型微调，英语：fine-tuning）是==深度学习中迁移学习的一种方法==，其中预训练模型的权重会在新数据上进行训练。微调可以在整个神经网络上执行，也可以仅在其部分层上执行，此时未进行微调的层会被“冻结”（在反向传播步骤中不更新） - Wikipedia 微调通常通过==监督学习==完成，但也有使用弱监督进行模型微调的技术。 - Wikipedia Low-rank adaptation (==LoRA==) is an adapter-based technique for efficiently fine-tuning models. - Wikipedia\nLLM 总不能样样精通.\n可以理解为：通过利用已有的知识来提高模型在新任务上的表现。\n任何预训练好的模型都能微调！预训练-微调方法属于基于模型的迁移方法（Parameter/Model-based TransferLearning）\n总结 角色 作用 依赖 知识库 ==专业知识库==，提供事实性、权威性的知识数据 被RAG或智能体查询 智能体 ==Agent==，负责与用户交互，并调用RAG或知识库来回答问题 可能使用RAG提升回答能力 RAG ==一种AI架构==，从知识库检索信息，并结合语言模型生成答案 需要知识库作为数据来源 微调 ==迁移学习的一种方法==，使通用模型适配特定领域任务 需要知识库作为微调数据 形象的比喻：微调是考前复习，RAG 是开卷考试。\n然而本地部署并微调一个大模型，对于个人来说成本是极大的；如果退而求其次，微调一个小一点的模型，效果又可能不好；所以实践证实:==在本地部署一个蒸馏版的大模型+RAG 技术是一个更优的解决方案==。\n","permalink":"https://iceyorange.github.io/posts/ai%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/%E7%9F%A5%E8%AF%86%E5%BA%93%E6%99%BA%E8%83%BD%E4%BD%93rag%E5%BE%AE%E8%B0%83/","summary":"本地部署都很吃配置 知识库 KB 知识库（Knowledge base）是用于知识管理的一种==特殊的数据库==，以便于有关领域知识的采集、整理以及提取。知识库中的知识源于领域专家，它是求解问题所需领域知识的集合，包括基本事实、规则和其它有关信息。 - Wikipedia 例如：法院判例库、医院病例库、产品数据","title":"知识库、智能体、RAG、微调"},{"content":" Name: Orange (Jude) Job: Student major in Statistics Interest: \u0026#x1f3c0;\u0026#x1f52d;\u0026#x1f3b8;\u0026#x1f3b5; Contact Information\nEmail: uasgwr@gmail.com\n","permalink":"https://iceyorange.github.io/about/","summary":"Name: Orange (Jude) Job: Student major in Statistics Interest: \u0026#x1f3c0;\u0026#x1f52d;\u0026#x1f3b8;\u0026#x1f3b5; Contact Information\nEmail: uasgwr@gmail.com","title":"About Me"},{"content":" 夜行人 A follower of Personal Computing ","permalink":"https://iceyorange.github.io/links/","summary":"夜行人 A follower of Personal Computing","title":"🤝Links"}]