<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>回归分析 | Lovegood&#39;s Blog</title>
<meta name="keywords" content="统计学">
<meta name="description" content="德国学者 Gauss (1777‐1855) 于 1809 年提出最小二乘法。 英国遗传学家 Galton (1822‐1911) 于 1886 年发表关于回归的开山论文 《遗传结构中向中⼼的回">
<meta name="author" content="Lovegood">
<link rel="canonical" href="https://20250303.xyz/posts/3.-resources-%E8%B5%84%E6%BA%90-%E6%9C%AA%E6%9D%A5/%E7%BB%9F%E8%AE%A1%E5%AD%A6-ml/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/">
<meta name="google-site-verification" content="G-LZESR1K8WK">

<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
  <meta name="referrer" content="no-referrer-when-downgrade">
<link crossorigin="anonymous" href="../../../../assets/css/stylesheet.css" rel="preload stylesheet" as="style">
<link rel="icon" href="https://20250303.xyz/img/xx.gif">
<link rel="icon" type="image/png" sizes="16x16" href="https://20250303.xyz/img/xx.gif">
<link rel="icon" type="image/png" sizes="32x32" href="https://20250303.xyz/img/xx.gif">
<link rel="apple-touch-icon" href="https://20250303.xyz/xx.gif">
<link rel="mask-icon" href="https://20250303.xyz/xx.gif">
<meta name="theme-color" content="#576175">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://20250303.xyz/posts/3.-resources-%E8%B5%84%E6%BA%90-%E6%9C%AA%E6%9D%A5/%E7%BB%9F%E8%AE%A1%E5%AD%A6-ml/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.css" integrity="sha384-bYdxxUwYipFNohQlHt0bjN/LCpueqWz13HufFEV1SUatKs1cm4L6fFgCi1jT643X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/katex.min.js" integrity="sha384-Qsn9KnoKISj6dI8g7p1HBlNpVx0I8p1SvlwOldgi3IorMle61nQy4zEahWYtljaz" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.2/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous"></script>
<script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement(document.body, {
          
          
          delimiters: [
              {left: '$$', right: '$$', display: true},
              {left: '$', right: '$', display: false},
              {left: '\\(', right: '\\)', display: false},
              {left: '\\[', right: '\\]', display: true}
          ],
          
          throwOnError : false
        });
    });
</script>



<link rel="stylesheet" href="https://cdn.staticfile.org/lxgw-wenkai-screen-webfont/1.6.0/style.css" />


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
    onload="renderMathInElement(document.body);"></script>

<script async src="https://www.googletagmanager.com/gtag/js?id=G-LZESR1K8WK"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-LZESR1K8WK', { 'anonymize_ip': false });
}
</script>
<meta property="og:title" content="回归分析" />
<meta property="og:description" content="德国学者 Gauss (1777‐1855) 于 1809 年提出最小二乘法。 英国遗传学家 Galton (1822‐1911) 于 1886 年发表关于回归的开山论文 《遗传结构中向中⼼的回" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://20250303.xyz/posts/3.-resources-%E8%B5%84%E6%BA%90-%E6%9C%AA%E6%9D%A5/%E7%BB%9F%E8%AE%A1%E5%AD%A6-ml/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2025-03-10T00:00:00+00:00" />
<meta property="article:modified_time" content="2025-03-20T00:00:00+00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="回归分析"/>
<meta name="twitter:description" content="德国学者 Gauss (1777‐1855) 于 1809 年提出最小二乘法。 英国遗传学家 Galton (1822‐1911) 于 1886 年发表关于回归的开山论文 《遗传结构中向中⼼的回"/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://20250303.xyz/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "回归分析",
      "item": "https://20250303.xyz/posts/3.-resources-%E8%B5%84%E6%BA%90-%E6%9C%AA%E6%9D%A5/%E7%BB%9F%E8%AE%A1%E5%AD%A6-ml/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "回归分析",
  "name": "回归分析",
  "description": "德国学者 Gauss (1777‐1855) 于 1809 年提出最小二乘法。 英国遗传学家 Galton (1822‐1911) 于 1886 年发表关于回归的开山论文 《遗传结构中向中⼼的回",
  "keywords": [
    "统计学"
  ],
  "articleBody": " 德国学者 Gauss (1777‐1855) 于 1809 年提出最小二乘法。 英国遗传学家 Galton (1822‐1911) 于 1886 年发表关于回归的开山论文 《遗传结构中向中⼼的回归》Regression towards Mediocrity in heredity structure)。[[统计学史#^tp89te]] 回归分析是处理变量之间的==相关关系==的⼀种统计⽅法和技术。\n相关分析：⽤⼀个指标 (相关系数) 来表明现象间相互依存关系的密切程度。以现象之间是否相关、相关的⽅向和密切程度等为研究内容，不区分⾃变量和因变量，不关⼼相关关系的表现形态。 回归分析：对具有相关关系的现象，根据其相关关系的具体形态，选择⼀个合适的数学模型 (回归⽅程) 来近似地表达变量间的平均变化关系。 相关分析是回归分析的基础和前提；回归分析是相关分析的深⼊和继续。 ⼴义的相关分析包括回归分析。 模型假设 样本回归模型 $y_i=\\beta_0+\\beta_1x_i+\\varepsilon_i$. 理论回归模型 $y=\\beta_0+\\beta_1x+\\varepsilon$. 经验回归方程 $\\hat{y}=\\hat{\\beta}_0+\\hat{\\beta}_1x$. 回归模型 $E(y|x)=\\beta_0+\\beta_1x$ 从平均意义上表达了变量 $y$ 与 $x$ 之间的统计规律性 如何理解回归模型中的条件期望？在给定解释变量 $X$ 取特定值 $x$ 时，被解释变量 $Y$ 的平均值。 回归分析的基本假定：\n因变量和自变量之间存在线性关系 观测值应该相互独立，避免自相关问题 残差应该近似服从正态分布，这一假定有助于进行统计推断和构建置信区间 残差的方差在不同自变量取值的情况下应该大致相等，避免异方差问题 自变量之间应该是线性无关的，避免多重共线性问题 自变量 x 为非随机变量 可以通过残差分析、散点图、Q-Q图等方法来检验这些基本假定的成立程度\n⚠️G-M 假设不要求扰动项服从正态分布！\n在高斯马尔科夫条件下，最小二乘估计是最佳线性无偏估计，即在所有线性无偏估计中具有最小方差（最有效），被称为BLUE（Best Linear Unbiased Estimators）。\n注意这里不是 MVUE (Best Linear Unbiased Estimator)：在所有无偏估计量中具有最小方差（最有效），MVUE 的条件要比 BLUE 更强（MVUE 是与所有无偏估计进行比较，既包括线性，又包括非线性；而 BLUE 则只是与所有线性无偏估计进行比较）。\n正态性假设: $\\varepsilon_i \\sim N(0, \\sigma^2)$, 且 $\\varepsilon_i$ 间相互独立。\n正态假定下 MLE 与 OLSE 等价，MLE最大化似然函数，OLSE最小化损失函数。\n⼀元线性回归中⾃变量和残差的关系：在⼀元线性回归模型中， ⾃变量 (X) 和残差 (ε) 理论上应该是独⽴的。残差代表了实际观测值与通过回归线预测值之间的差异。如果⾃变量和残差不独⽴，可能表明模型中存在遗漏变量或⾮线性关系没有被正确模型化。\n最小二乘估计和最大似然估计是否都符合无偏性？回归系数均无偏，方差均无偏（需修正）\n模型的显著性检验 F 检验：整体回归模型的显著性检验。先进行 F-test 检验整体，再使用 t-test 检验单个。 t 检验：单个回归系数的显著性检验； 相关系数的显著性检验（或称样本决定系数的显著性检验）, 利用 $r^2=\\frac{F}{F+(n-2)}$. 以上三个检验再一元线性回归时是等价的，但在多元线性回归场合，经推广 F 检验仍可用，另两个检验就无法使用了。\n违背基本假设的几种情况 相较于一元线性回归，多元线性回归面临着额外的几个问题：\n多重共线性； 变量数量变多时，易导致模型复杂度增加，易造成过拟合，影响模型泛化能力； 各变量尺度不一样，需要进行数据标准化； 变量之间可能存在非线性关系或交互作用； 1. 多重共线性\n定义：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。\n原因：经济变量之间的共同变化趋势、利用截面数据建立模型的问题、模型中包含滞后变量、样本自身数据的原因。\n问题：$\\beta$ 方差 $\\sigma^2(X’X)^{-1}$ 偏大，估计精度低，不稳定，t 统计量↓，不易拒绝 $H_0$.\n诊断：容忍度 $1-R_j^2$ ＜0.1、方差扩大因子 $VIF_j=\\frac{1}{1-R_j^2}≥10$、条件数 $=\\frac{\\lambda_{max}}{\\lambda_{min}}≥100$、直接看特征根（是否接近 0）\n解决⽅法：可以通过以下方法来解决：\n变量选择； 增加样本观测量：对时间序列资料就是增大观测次数，对截面数据资料就是增加观测对象； 利用先验信息：把事先知道的关系包含近回归模型中； 横截面数据和时间序列数据并用。 使⽤主成分回归（PCR），$X$ 中有多重共线性的变量，那就不使用 $X$ 来进行回归分析，转而==使用 $X$ 对应的主成分矩阵==。 偏最小二乘法：相较于通过寻找响应和独立变量之间最小方差的超平面，偏最小二乘法通过==投影预测变量和观测变量到一个新空间==来寻找一个线性回归模型。 岭回归（$X’X$ 不可逆？那就==加上一个正则项== $X’X+kI$ 这样就可逆了），代价是：有偏。通过岭迹图来确定 $k$ 值岭迹图图片 Lasso 回归。详见下图： 图源博客园博文 注意：不是说一个模型有多重共线性情况，那这个模型就完全不行。如果说是利用模型去做经济结构分析，那么要尽可能避免多重共线性；==而如果说只是利用模型去做经济预测，只要保证自变量的相关类型在未来时期中保持不变，即使回归模型中含有严重多重共线性的变量，也可以得到较好的预测结果。==\n2. 异⽅差性\n原因：省略重要解释变量、测量误差、模型函数设定错误、截面数据中总体各单位的差异。 问题： 虽参数仍是无偏估计（OLSE 的无偏性仅依赖于随机误差项的零均值假设），但不是 MVUE（依赖 G-M 条件）； 参数方差的估计量是有偏的（虽然就算没有出现异方差情况也是无偏的）； 显著性检验失效，回归方程应用效果不理想。 诊断：绘制残差图、斯皮尔曼等级相关系数检验、white 检验 解决⽅法：可以使⽤加权最小二乘法，通过给不同的观测值赋予不同的权重 $w_i$，使误差较大的样本权重较小，从而改进估计；或对变量进⾏变换（BOX-COX）。 3. ⾃相关\n产生原因：被解释变量的自相关、遗漏关键变量、随机误差项的自相关、经济变量的滞后性（惯性）、回归函数的错误、蛛网现象、不恰当的数据预处理方式（如差分变换） 问题：斜率系数的最小二乘估计量仍然线性无偏（参数OLSE 的无偏性仅依赖于随机误差项的零均值假定），但参数方程仍然有偏；预测的精确度降低；t 值↑，易犯拒真错误；估计值不再是 MVUE；MES 严重↓ 诊断：绘制 $e_i, e_{i-1}$ 散点图、绘制 $e_t$ 时间序列图、自相关系数绝对值接近 1、DW 值离 2 的距离越远自相关越严重。 解决⽅法：迭代法、差分法、广义最小二乘法（GLS）、时间序列模型（如 ARIMA）或对数据进行BOX-COX 变换。 4. ⾮线性关系\n问题：如果因变量与⾃变量之间的关系是⾮线性的，线性回归模型⽆法准确描述这种关系。 解决⽅法：可以使⽤⾮线性回归模型，或者对变量进⾏变换（如对数变换、多项式回归）。 5. 数据量不⾜\n问题：如果样本量太少，回归模型的参数估计可能不准确，模型容易过拟合。 解决⽅法：增加数据量，或者使⽤正则化⽅法（如 Lasso 回归）来防⽌过拟合。 6. 忽略重要变量\n问题：如果模型中遗漏了重要的⾃变量，会导致回归系数估计有偏。 解决⽅法：通过领域知识或变量选择⽅法（如逐步回归）来识别重要变量。 7. 异常点、高杠杆点与强影响点\n注意：异常点不一定是强影响点，强影响点也不一定是异常点、高杠杆点不一定是强影响点，强影响点也不一定是高杠杆点。 问题：异常值会对回归模型的拟合产⽣较⼤影响，导致模型失真。 解决⽅法：可以通过剔除异常值或使⽤稳健回归⽅法。 诊断： 参考 判断异常点，异常值点：对既定模型偏离很⼤的数据点 标准化残差 $ZRE_i=\\frac{e_i}{\\hat{\\sigma}}$ 绝对值＞3 学生化残差 $SRE=\\frac{e_i}{\\hat{\\sigma}\\sqrt{1-h_{ii}}}$ 绝对值＞3, 相较于标准化残差，学生化残差剔除了高杠杆值的影响； 判断高杠杆点：杠杆值 $h_{ii}=\\frac{1}{n}+\\frac{(x_i-\\bar{x})^2}{\\sum_{j = 0}^{n} (x_j-\\bar{x})^2}$, ==高杠杆点≠强影响点≠异常点==，在⾃变量空间中远离数据中⼼的点，有==把拟合直线拖向⾃⼰==的倾向，称之为⾼杠杆点 判断强影响点：库克距离 $D_i=\\frac{\\sum_{j = 0}^{n} (y_j-y_{j(i)})^2}{p ·MSE}$ ＞0.5, 度量去除某一数据点后其它样本拟合值的变化。强影响点是对统计推断产⽣较⼤影响的数据点，删除该点会导致拟合模型的实质性变化，如参数估计值、拟合值或检验值发⽣较⼤变化。==库克距离是一个综合指标，结合了杠杆值和残差大小，用来评估数据点对回归系数估计的整体影响。== 变量选择中评价模型的指标 自由度调整复决定系数越大越好； AIC 和 BIC：这两个准则都是基于似然函数，考虑了模型复杂度的惩罚。在⽐较多个模型时，AIC 和BIC 较⼩的模型被认为更优； ^grw9h5 $C_p$ 统计量越小越好； 调整 $R^2$：对 $R^2$ 进⾏调整，考虑了模型中变量的数量。在模型中添加更多变量时，即使这些变量对模型的贡献很⼩，$R^2$ 也可能会增加。调整后的 $R^2$ 提供了⼀个更为准确的衡量标准。 残差图分析：通过观察残差（实际值与预测值之差）的分布情况，可以评估模型是否满⾜线性回归的假设，例如残差的独⽴性、正态性和⽅差⻬性。 下面这几个有些许风险：选择解释变量时不应以 SSE 为标准，因为变量↑，SSE 一定↓（想象过拟合，调整 $R^2$ 就解决了这个问题），可以看看各变量系数是否显著。 均⽅误差：计算模型预测值与实际值差值的平⽅的平均值。MSE 越⼩，模型的预测准确度越⾼ 。 均⽅根误差：MSE 的平⽅根。RMSE 是衡量模型预测误差的常⽤标准，越⼩表示模型预测越准确。 平均绝对误差：计算模型预测值与实际值差值的绝对值的平均值。MAE 提供了预测误差的另⼀种衡量，对异常值的敏感度低于 MSE。 决定系数：衡量模型预测值的变异性占总变异性的比例，值范围从 0 到 1。$R^2$ 值越接近 1 ，表示模型解释的变异性越⼤，拟合度越好。 选择合适的评估⽅法取决于具体的研究目的和数据特性。通常，结合使⽤多种评估指标可以更全⾯地了解回归模型的性能。\n❗注意弄清楚 F 检验统计量和 $R^2$ 的表达式: $F=\\frac{MSR}{MSE}$, $R^2=\\frac{SSR}{SST}$\n$$ R^2=\\frac{SSR}{SST}=\\frac{\\sum (\\hat{y_i}-\\bar{y_i})^2}{\\sum (y_i-\\bar{y})^2}=\\frac{\\sum (\\hat{\\beta_0}+\\hat{\\beta_1}x_i-\\hat{\\beta_0}-\\hat{\\beta_1}\\bar{x})^2}{L_{yy}}=\\frac{\\hat{\\beta_1}^2 \\sum (x_i-\\bar{x})^2}{L_{yy}}=\\frac{\\hat{\\beta_1}^2L_{xx}}{L_{yy}} $$\n其中 $\\hat{\\beta_1}^2=(\\frac{L_{xy}}{L_{xx}})^2$, 故 $R^2=\\frac{L_{xy}^2}{L_{xx}·L_{yy}}=(\\frac{L_{xy}}{\\sqrt{L_{xx}L_{yy}}})^2=r^2$.\n$$ F=\\frac{MSR}{MSE}=\\frac{SSR/1}{SSE/(n-2)}=\\frac{(n-2)SSR}{SSE}=(n-2)\\frac{SSR}{SST-SSR}=(n-2)\\frac{R^2}{1-R^2} $$\n注意这里的自由度要根据实际情况调整。\n$$ t=\\frac{\\hat{\\beta_1}\\sqrt{L_{xx}}}{\\hat{\\sigma}}\\overset{分解\\hat{\\beta_1}}{=}\\frac{r·\\sqrt{L_{yy}}}{\\sqrt{L_{xx}}}·\\frac{\\sqrt{L_{xx}}}{\\hat{\\sigma}}=\\frac{r·\\sqrt{L_{yy}}}{\\sqrt{SSE/(n-2)}}\\overset{L_{yy}=SST}{=}r·\\sqrt{n-2}·\\sqrt{\\frac{SST}{SSE}}=\\frac{r·\\sqrt{n-2}}{\\sqrt{1-r^2}} $$\n误差、残差与偏差 误差:观测值与真实值的偏离，如多次测量取平均值中的“测量误差”； 残差:观测值与模型估计值的偏离，理想情况下，如果模型是最优的，并且符合假设（如线性回归假设误差是独立同分布的），那么残差可以被视为==随机噪声==。但如果模型存在欠拟合、遗漏变量、异方差性等问题，==残差可能不仅仅是随机噪声，而是包含了系统性误差==。 偏差:观测值与模型估计值的偏离，排除噪声的影响，偏差是模型无法准确表达数据关系导致，比如模型过于简单，非线性的数据关系采用线性模型建模等，反映模型本身的精确度。 注：左图来自论文，右图来自文章\n针对欠拟合和过拟合的处理方式如下：\n欠拟合：偏差过大，做特征工程、减小(弱) 正则化系数； 过拟合：方差过大，可增加样本、减少特征、增加(强)正则化系数； 过拟合会导致方差偏大，核心原因在于模型对训练数据的依赖过强，从而导致其泛化能力下降。在偏差-方差分解（Bias-Variance Tradeoff）中：$\\mathbb{E}[(\\hat{y} - y)^2] = \\text{Bias}^2 + \\text{Variance} + \\text{Noise}$\n过拟合时，模型在训练集上的偏差几乎总是很小，而在验证集上，偏差可能不明显，但高方差会导致测试误差增大。\n过拟合会导致方差偏大的本质原因是模型对训练数据的学习过度，使得它对新数据的预测波动性增加，从而导致测试误差的不稳定性。这也就是为什么在深度学习或机器学习任务中，我们通常需要正则化（如L1/L2正则化、Dropout）、数据增强或早停（Early Stopping）等方法来降低方差，提高泛化能力。\n残差分析中的 QQ 图：用于对残差进行正态性检验（P-P图和Q-Q图都是用于检验样本的概率分布是否服从某种理论分布。一定要严格落在对角线上吗？普通直线行不行？Ans: 行！残差近似于⼀条直线：说明残差的分布与正态分布⾮常接近，即残差基本服从正态分布）\n各种“系数”概念辨析 决定系数（又称拟合优度、判定系数） $R^2 = \\frac{SSR}{SST} = \\frac{\\sum_{i=1}^{n} (\\hat{y}_i - \\overline{y})^2}{\\sum_{i=1}^{n} (y_i - \\overline{y})^2}$. 它指的是回归平方和占总平方和的比重, 表示自变量对因变量随机性的解释比例, 同时也反映了自变量和因变量的线性相关性强弱。\n分为一元和多元两个情形讨论。\n一元情形 Pearson 相关系数的平方 $r^2$ = 决定系数 $R^2$ （又称拟合优度、判定系数）\n多元情形 偏相关系数：在控制其他变量的影响后，两个变量之间的净相关关系。\n复相关系数 R：因变量 Y 与多个自变量的线性组合之间的相关系数。\n决定系数 $R^2$ =复相关系数 R 的平方。\n区间估计 \u0026 区间预测 有截距项 Vs 无截距项 有截距项回归模型残差和为 0；无截距项回归模型残差和不一定为 0\n下面讨论方差分析自由度，其中 k 为自变量个数。⚠️==不同教材对 k 的定义可能不一样！==\n有截距项方差分析，实际参数为 k+1 个(截距项)，自由度: SST: n-1, SSR: k, SSE: n-k-1 无截距项方差分析，实际参数就是 k 个，自由度: SST: n, SSR: k, SSE: n-k 在回归分析中，如何处理无序变量？ 分两种情况：自变量是无序变量、因变量是无序变量（Logistic 回归，在线性回归的基础上加了一个 Sigmoid 函数（非线形）映射，使得逻辑回归称为了一个优秀的分类算法）。\n下面详细写写自变量是无序变量的情形：\n处理无序变量，核心思想就是“编码”，参考 解决（几乎）任何机器学习问题：处理分类变量篇（上篇）\n设置哑变量。哑变量：又称为虚拟变量、虚设变量或名义变量。对于有n个分类属性的自变量，通常需要选取1个分类作为参照，因此可以产生n-1个哑变量。==哑变量即 One-Hot Encoding!==\n当回归模型有截距项时，只能引入 m-1 个虚拟变量，否则就会陷入“虚拟变量陷阱”；当回归模型无截距项时，可以引入 m 个虚拟变量。\nOne-Hot Encoding：这是最基础也是最常见的转换手段之一。它会给每个类别创建一个新的二进制列，并标记是否存在该值(0 或者 1)。然而这种方法可能会导致维度爆炸的问题，在类别过多的情况下生成大量的新特性。\n下面的其它 Encoding 方法先浅浅涉猎，在归纳机器学习的时候再深入了解。\nBinary Encoding; BaseN Encoding; Target Encoding / Mean Encoding; Feature Hashing (Hash Trick). 写在后面 - 区分回归关系、因果关系和相关关系 先说回归关系和相关关系的区别：回归关系是有方向性的，解释一个变量对另一个变量的影响，即区分因变量和自变量；而相关关系是没有方向的，变量间的地位是对等的。\n下面着重介绍一下因果关系和相关关系的区别与联系：\n因果关系的证明通常不是来自于单独的统计检验，而是来自于谨慎的实验设计。\n鉴别因果性最好和最科学的方法就是控制变量与盲测，例如美国FDD药品测试的随机双盲测试。\n图灵奖得主、“贝叶斯网络之父” Judea Pearl写了一本书，《为什么：关于因果关系的新科学》, 阐述了因果之梯：从低到高分别是：关联、干预、反事实推理。\n第一层级是关联（Association），即相关关系：“事件A发生时，事件B也发生”。注意：并不能得出事件之间的影响方向，比如是不是因为事件A的发生导致了事件B的发生。\n第二层级是干预（Intervention），当通过干预使事件A 发生改变时，事件B是否会跟着随之改变。\n第三层级是反事实（Counterfactual），借由想象（Imaging），也可以理解为“执果索因”、“以终推始”，可以想象下，如果想让事件B发生某种变化时，能否通过改变事件A来实现。\n参考这篇知乎文章。\n等复试完看看这本书 ",
  "wordCount" : "6237",
  "inLanguage": "en",
  "datePublished": "2025-03-10T00:00:00Z",
  "dateModified": "2025-03-20T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": "Lovegood"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://20250303.xyz/posts/3.-resources-%E8%B5%84%E6%BA%90-%E6%9C%AA%E6%9D%A5/%E7%BB%9F%E8%AE%A1%E5%AD%A6-ml/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Lovegood's Blog",
    "logo": {
      "@type": "ImageObject",
      "url": "https://20250303.xyz/img/xx.gif"
    }
  }
}
</script>
</head>

<body class=" dark" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://20250303.xyz/" accesskey="h" title="Lovegood&#39;s Blog (Alt + H)">
                <img src="https://20250303.xyz/img/xx.gif" alt="" aria-label="logo"
                    height="35">Lovegood&#39;s Blog</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://20250303.xyz/search" title="🔍搜索 (Alt &#43; /)" accesskey=/>
                    <span>🔍搜索</span>
                </a>
            </li>
            <li>
                <a href="https://20250303.xyz/" title="🏠主页">
                    <span>🏠主页</span>
                </a>
            </li>
            <li>
                <a href="https://20250303.xyz/posts" title="📚博文">
                    <span>📚博文</span>
                </a>
            </li>
            <li>
                <a href="https://20250303.xyz/archives/" title="⏱时间轴">
                    <span>⏱时间轴</span>
                </a>
            </li>
            <li>
                <a href="https://20250303.xyz/tags" title="🔖标签">
                    <span>🔖标签</span>
                </a>
            </li>
            <li>
                <a href="https://20250303.xyz/about" title="🙋🏻‍♂️关于我">
                    <span>🙋🏻‍♂️关于我</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">
<style>
  i[id*="post_meta_style"] {
    display: flex;
    align-items: center;
    margin: 0 0 10px 0;
  }
</style>

<article class="post-single">
  <div id="single-content">
  <div id="single-content">
    <header class="post-header">
      <div class="breadcrumbs"><a href="https://20250303.xyz/">Home</a>&nbsp;»&nbsp;<a href="https://20250303.xyz/posts/">Posts</a></div>
      <h1 class="post-title">
        回归分析
      </h1>
      <div class="post-meta">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@4.7.0/css/font-awesome.min.css">
<style>
    i[id*="post_meta_style"] {
        display: flex;
        align-items: center;
        margin: 0 0 10px 0;
    }

    .parent-post-meta {
        display: flex;
        flex-wrap: wrap;
        opacity: 0.8;
    }
</style>

<span class="parent-post-meta">
    <span id="post_meta_style_1">
        <span class="fa fa-calendar-check-o"></span>
        <span>2025-03-10
            &nbsp;&nbsp;
        </span>
    </span>
    
    <span id="post_meta_style_3">
        <span class="fa fa-file-word-o"></span>
        <span>6237 words
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_4">
        <span class="fa fa-clock-o"></span>
        <span>13 minutes
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_5">
        <span class="fa fa-user-o"></span>
        <span>Lovegood
            &nbsp;&nbsp;
        </span>
    </span>
    <span id="post_meta_style_6">
        <span class="fa fa-tags" style="opacity: 0.8"></span>
        <span>
            <span class="post-tags-meta">
                <a href="https://20250303.xyz/tags/%E7%BB%9F%E8%AE%A1%E5%AD%A6/" style="color: var(--secondary)!important;">统计学</a>
            </span>
        </span>
    </span>
</span>
        
        <span style="opacity: 0.8;">
          <span id="post_meta_style_7">
            &nbsp;&nbsp;
            <span class="fa fa-eye"></span>
            <span>
              <span id="busuanzi_container_page_pv"><span id="busuanzi_value_page_pv"></span></span>
              &nbsp;&nbsp;
            </span>
          </span>
          <span id="post_meta_style_8">
            <span class="fa fa-commenting-o"></span>
            <span>
              <script
                src="https://cdn.staticfile.org/twikoo/1.6.41/twikoo.all.min.js"></script>
              <script>
                let url = document.documentURI
                
                let dnsUrl = "https://20250303.xyz/"
                let urlSplit = url.split(dnsUrl)
                let finalUrl = urlSplit[1]
                if (finalUrl[0] !== '/') {
                  finalUrl = '/' + finalUrl
                }
                twikoo.getCommentsCount({
                  envId: "https://twikoo.20250303.xyz", 
                  region:  null , 
                  urls: [ 
                  
                  finalUrl,
                ],
                  includeReply: false 
                                }).then(function (res) {
                    let count = res[0].count
                    const obj = document.getElementById("comment_count");
                    obj.innerText = count
                    
                    
                    
                  }).catch(function (err) {
                    
                    console.error(err);
                  });
              </script>
              <span id="comment_count"></span>
            </span>
          </span>
        </span>

</div>
    </header>   <div class="toc">
    <details  open>
      <summary accesskey="c" title="(Alt + C)">
        <div class="details">回归分析</div>
      </summary>
      <div class="inner"><ul><li>
        <a href="#%e6%a8%a1%e5%9e%8b%e5%81%87%e8%ae%be" aria-label="模型假设">模型假设</a></li><li>
        <a href="#%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%98%be%e8%91%97%e6%80%a7%e6%a3%80%e9%aa%8c" aria-label="模型的显著性检验">模型的显著性检验</a></li><li>
        <a href="#%e8%bf%9d%e8%83%8c%e5%9f%ba%e6%9c%ac%e5%81%87%e8%ae%be%e7%9a%84%e5%87%a0%e7%a7%8d%e6%83%85%e5%86%b5" aria-label="违背基本假设的几种情况">违背基本假设的几种情况</a></li><li>
        <a href="#%e5%8f%98%e9%87%8f%e9%80%89%e6%8b%a9%e4%b8%ad%e8%af%84%e4%bb%b7%e6%a8%a1%e5%9e%8b%e7%9a%84%e6%8c%87%e6%a0%87" aria-label="变量选择中评价模型的指标">变量选择中评价模型的指标</a></li><li>
        <a href="#%e8%af%af%e5%b7%ae%e6%ae%8b%e5%b7%ae%e4%b8%8e%e5%81%8f%e5%b7%ae" aria-label="误差、残差与偏差">误差、残差与偏差</a></li><li>
        <a href="#%e5%90%84%e7%a7%8d%e7%b3%bb%e6%95%b0%e6%a6%82%e5%bf%b5%e8%be%a8%e6%9e%90" aria-label="各种“系数”概念辨析">各种“系数”概念辨析</a><ul>
            <li>
        <a href="#%e4%b8%80%e5%85%83%e6%83%85%e5%bd%a2" aria-label="一元情形">一元情形</a></li><li>
        <a href="#%e5%a4%9a%e5%85%83%e6%83%85%e5%bd%a2" aria-label="多元情形">多元情形</a></li></ul>
    </li><li>
        <a href="#%e5%8c%ba%e9%97%b4%e4%bc%b0%e8%ae%a1--%e5%8c%ba%e9%97%b4%e9%a2%84%e6%b5%8b" aria-label="区间估计 &amp;amp; 区间预测">区间估计 &amp; 区间预测</a></li><li>
        <a href="#%e6%9c%89%e6%88%aa%e8%b7%9d%e9%a1%b9-vs-%e6%97%a0%e6%88%aa%e8%b7%9d%e9%a1%b9" aria-label="有截距项 Vs 无截距项">有截距项 Vs 无截距项</a></li><li>
        <a href="#%e5%9c%a8%e5%9b%9e%e5%bd%92%e5%88%86%e6%9e%90%e4%b8%ad%e5%a6%82%e4%bd%95%e5%a4%84%e7%90%86%e6%97%a0%e5%ba%8f%e5%8f%98%e9%87%8f" aria-label="在回归分析中，如何处理无序变量？">在回归分析中，如何处理无序变量？</a></li><li>
        <a href="#%e5%86%99%e5%9c%a8%e5%90%8e%e9%9d%a2---%e5%8c%ba%e5%88%86%e5%9b%9e%e5%bd%92%e5%85%b3%e7%b3%bb%e5%9b%a0%e6%9e%9c%e5%85%b3%e7%b3%bb%e5%92%8c%e7%9b%b8%e5%85%b3%e5%85%b3%e7%b3%bb" aria-label="写在后面 - 区分回归关系、因果关系和相关关系">写在后面 - 区分回归关系、因果关系和相关关系</a></li></ul></div>
    </details>
  </div>
    <div class="post-content">
      <ul>
<li>德国学者 Gauss (1777‐1855) 于 1809 年提出最小二乘法。</li>
<li>英国遗传学家 Galton (1822‐1911) 于 1886 年发表关于回归的开山论文 《遗传结构中向中⼼的回归》Regression towards Mediocrity in heredity structure)。[[统计学史#^tp89te]]</li>
</ul>
<p>回归分析是处理变量之间的<mark>相关关系</mark>的⼀种统计⽅法和技术。</p>
<ul>
<li>相关分析：⽤⼀个指标 (相关系数) 来表明现象间相互依存关系的密切程度。以现象之间是否相关、相关的⽅向和密切程度等为研究内容，不区分⾃变量和因变量，不关⼼相关关系的表现形态。</li>
<li>回归分析：对具有相关关系的现象，根据其相关关系的具体形态，选择⼀个合适的数学模型 (回归⽅程) 来近似地表达变量间的平均变化关系。</li>
<li>相关分析是回归分析的基础和前提；回归分析是相关分析的深⼊和继续。</li>
<li>⼴义的相关分析包括回归分析。</li>
</ul>
<p><img loading="lazy" src="https://pictest.20250303.xyz/img/202503102042932.png" alt="image.png"  />
</p>
<hr>
<h2 id="模型假设">模型假设<a hidden class="anchor" aria-hidden="true" href="#模型假设">#</a></h2>
<ul>
<li>样本回归模型 $y_i=\beta_0+\beta_1x_i+\varepsilon_i$.</li>
<li>理论回归模型 $y=\beta_0+\beta_1x+\varepsilon$.</li>
<li>经验回归方程 $\hat{y}=\hat{\beta}_0+\hat{\beta}_1x$.</li>
<li>回归模型 $E(y|x)=\beta_0+\beta_1x$ 从平均意义上表达了变量 $y$ 与 $x$ 之间的统计规律性</li>
<li>如何理解回归模型中的条件期望？在给定解释变量 $X$ 取特定值 $x$ 时，被解释变量 $Y$ 的平均值。 <img loading="lazy" src="https://encrypted-tbn3.gstatic.com/images?q=tbn:ANd9GcQhs6QTIRaoIu-uMLo1qAkWbAjQV8zQMrdWuZkO9QHptDzLJ19G" alt="图片"  />
</li>
</ul>
<p>回归分析的基本假定：</p>
<ol>
<li>因变量和自变量之间存在线性关系</li>
<li>观测值应该相互独立，避免自相关问题</li>
<li>残差应该近似服从正态分布，这一假定有助于进行统计推断和构建置信区间</li>
<li>残差的方差在不同自变量取值的情况下应该大致相等，避免异方差问题</li>
<li>自变量之间应该是线性无关的，避免多重共线性问题</li>
<li>自变量 x 为非随机变量</li>
</ol>
<p>可以通过残差分析、散点图、Q-Q图等方法来检验这些基本假定的成立程度</p>
<p><img loading="lazy" src="https://pictest.20250303.xyz/img/202503102048043.png" alt="image.png"  />
</p>
<p>⚠️G-M 假设不要求扰动项服从正态分布！</p>
<p>在高斯马尔科夫条件下，最小二乘估计是最佳线性无偏估计，即在所有线性无偏估计中具有最小方差（最有效），被称为BLUE（Best Linear Unbiased Estimators）。</p>
<p>注意这里不是 MVUE (Best Linear Unbiased Estimator)：在所有无偏估计量中具有最小方差（最有效），MVUE 的条件要比 BLUE 更强（MVUE 是与所有无偏估计进行比较，既包括线性，又包括非线性；而 BLUE 则只是与所有线性无偏估计进行比较）。</p>
<p>正态性假设: $\varepsilon_i \sim N(0, \sigma^2)$, 且 $\varepsilon_i$ 间相互独立。</p>
<p>正态假定下 MLE 与 OLSE 等价，MLE最大化似然函数，OLSE最小化损失函数。</p>
<blockquote>
<p>⼀元线性回归中⾃变量和残差的关系：在⼀元线性回归模型中， ⾃变量 (X) 和残差 (ε) 理论上应该是独⽴的。残差代表了实际观测值与通过回归线预测值之间的差异。如果⾃变量和残差不独⽴，可能表明模型中存在遗漏变量或⾮线性关系没有被正确模型化。</p>
</blockquote>
<p>最小二乘估计和最大似然估计是否都符合无偏性？回归系数均无偏，方差均无偏（需修正）</p>
<hr>
<h2 id="模型的显著性检验">模型的显著性检验<a hidden class="anchor" aria-hidden="true" href="#模型的显著性检验">#</a></h2>
<ol>
<li>F 检验：整体回归模型的显著性检验。先进行 F-test 检验整体，再使用 t-test 检验单个。</li>
<li>t 检验：单个回归系数的显著性检验；</li>
<li>相关系数的显著性检验（或称样本决定系数的显著性检验）, 利用 $r^2=\frac{F}{F+(n-2)}$.</li>
</ol>
<p>以上三个检验再一元线性回归时是等价的，但在多元线性回归场合，经推广 F 检验仍可用，另两个检验就无法使用了。</p>
<hr>
<h2 id="违背基本假设的几种情况">违背基本假设的几种情况<a hidden class="anchor" aria-hidden="true" href="#违背基本假设的几种情况">#</a></h2>
<p>相较于一元线性回归，多元线性回归面临着额外的几个问题：</p>
<ul>
<li>多重共线性；</li>
<li>变量数量变多时，易导致模型复杂度增加，易造成过拟合，影响模型泛化能力；</li>
<li>各变量尺度不一样，需要进行数据标准化；</li>
<li>变量之间可能存在非线性关系或交互作用；</li>
</ul>
<p><strong>1. 多重共线性</strong></p>
<ul>
<li>
<p>定义：多变量线性回归中，变量之间由于存在高度相关关系而使回归估计不准确。</p>
</li>
<li>
<p>原因：经济变量之间的共同变化趋势、利用截面数据建立模型的问题、模型中包含滞后变量、样本自身数据的原因。</p>
</li>
<li>
<p>问题：$\beta$ 方差 $\sigma^2(X&rsquo;X)^{-1}$ 偏大，估计精度低，不稳定，t 统计量↓，不易拒绝 $H_0$.</p>
</li>
<li>
<p>诊断：容忍度 $1-R_j^2$ ＜0.1、方差扩大因子 $VIF_j=\frac{1}{1-R_j^2}≥10$、条件数 $=\frac{\lambda_{max}}{\lambda_{min}}≥100$、直接看特征根（是否接近 0）</p>
</li>
<li>
<p>解决⽅法：可以通过以下方法来解决：</p>
<ul>
<li>变量选择；</li>
<li>增加样本观测量：对时间序列资料就是增大观测次数，对截面数据资料就是增加观测对象；</li>
<li>利用先验信息：把事先知道的关系包含近回归模型中；</li>
<li>横截面数据和时间序列数据并用。</li>
<li>使⽤主成分回归（PCR），$X$ 中有多重共线性的变量，那就不使用 $X$ 来进行回归分析，转而<mark>使用 $X$ 对应的主成分矩阵</mark>。</li>
<li>偏最小二乘法：相较于通过寻找响应和独立变量之间最小方差的超平面，偏最小二乘法通过<mark>投影预测变量和观测变量到一个新空间</mark>来寻找一个线性回归模型。</li>
<li>岭回归（$X&rsquo;X$ 不可逆？那就<mark>加上一个正则项</mark> $X&rsquo;X+kI$ 这样就可逆了），代价是：有偏。通过岭迹图来确定 $k$ 值<a href="https://pictest.20250303.xyz/img/202503131644994.png">岭迹图图片</a></li>
<li>Lasso 回归。详见下图： <img loading="lazy" src="https://pictest.20250303.xyz/img/202503102147535.png" alt="image.png"  />
 图源<a href="https://www.cnblogs.com/wuliytTaotao/p/10837533.html">博客园博文</a></li>
</ul>
</li>
<li>
<p>注意：不是说一个模型有多重共线性情况，那这个模型就完全不行。如果说是利用模型去做经济结构分析，那么要尽可能避免多重共线性；<mark>而如果说只是利用模型去做经济预测，只要保证自变量的相关类型在未来时期中保持不变，即使回归模型中含有严重多重共线性的变量，也可以得到较好的预测结果。</mark></p>
</li>
</ul>
<p><strong>2. 异⽅差性</strong></p>
<ul>
<li>原因：省略重要解释变量、测量误差、模型函数设定错误、截面数据中总体各单位的差异。</li>
<li>问题：
<ul>
<li>虽参数仍是无偏估计（OLSE 的无偏性仅依赖于随机误差项的零均值假设），但不是 MVUE（依赖 G-M 条件）；</li>
<li>参数方差的估计量是有偏的（虽然就算没有出现异方差情况也是无偏的）；</li>
<li>显著性检验失效，回归方程应用效果不理想。</li>
</ul>
</li>
<li>诊断：绘制残差图、斯皮尔曼等级相关系数检验、white 检验</li>
<li>解决⽅法：可以使⽤加权最小二乘法，通过给不同的观测值赋予不同的权重 $w_i$，使误差较大的样本权重较小，从而改进估计；或对变量进⾏变换（BOX-COX）。</li>
</ul>
<p><strong>3. ⾃相关</strong></p>
<ul>
<li>产生原因：被解释变量的自相关、遗漏关键变量、随机误差项的自相关、经济变量的滞后性（惯性）、回归函数的错误、蛛网现象、不恰当的数据预处理方式（如差分变换）</li>
<li>问题：斜率系数的最小二乘估计量仍然线性无偏（参数OLSE 的无偏性仅依赖于随机误差项的零均值假定），但参数方程仍然有偏；预测的精确度降低；t 值↑，易犯拒真错误；估计值不再是 MVUE；MES 严重↓</li>
<li>诊断：绘制 $e_i, e_{i-1}$ 散点图、绘制 $e_t$ 时间序列图、自相关系数绝对值接近 1、DW 值离 2 的距离越远自相关越严重。</li>
<li>解决⽅法：迭代法、差分法、广义最小二乘法（GLS）、时间序列模型（如 ARIMA）或对数据进行BOX-COX 变换。</li>
</ul>
<p><strong>4. ⾮线性关系</strong></p>
<ul>
<li>问题：如果因变量与⾃变量之间的关系是⾮线性的，线性回归模型⽆法准确描述这种关系。</li>
<li>解决⽅法：可以使⽤⾮线性回归模型，或者对变量进⾏变换（如对数变换、多项式回归）。</li>
</ul>
<p><strong>5. 数据量不⾜</strong></p>
<ul>
<li>问题：如果样本量太少，回归模型的参数估计可能不准确，模型容易过拟合。</li>
<li>解决⽅法：增加数据量，或者使⽤正则化⽅法（如 Lasso 回归）来防⽌过拟合。</li>
</ul>
<p><strong>6. 忽略重要变量</strong></p>
<ul>
<li>问题：如果模型中遗漏了重要的⾃变量，会导致回归系数估计有偏。</li>
<li>解决⽅法：通过领域知识或变量选择⽅法（如逐步回归）来识别重要变量。</li>
</ul>
<p><strong>7. 异常点、高杠杆点与强影响点</strong></p>
<ul>
<li>注意：异常点不一定是强影响点，强影响点也不一定是异常点、高杠杆点不一定是强影响点，强影响点也不一定是高杠杆点。</li>
<li>问题：异常值会对回归模型的拟合产⽣较⼤影响，导致模型失真。</li>
<li>解决⽅法：可以通过剔除异常值或使⽤稳健回归⽅法。</li>
<li>诊断： <a href="https://my.oschina.net/u/4397001/blog/3421364">参考</a>
<ul>
<li>判断异常点，异常值点：对既定模型偏离很⼤的数据点
<ul>
<li>标准化残差 $ZRE_i=\frac{e_i}{\hat{\sigma}}$ 绝对值＞3</li>
<li>学生化残差 $SRE=\frac{e_i}{\hat{\sigma}\sqrt{1-h_{ii}}}$ 绝对值＞3, 相较于标准化残差，学生化残差剔除了高杠杆值的影响；</li>
</ul>
</li>
<li>判断高杠杆点：杠杆值 $h_{ii}=\frac{1}{n}+\frac{(x_i-\bar{x})^2}{\sum_{j = 0}^{n} (x_j-\bar{x})^2}$, <mark>高杠杆点≠强影响点≠异常点</mark>，在⾃变量空间中远离数据中⼼的点，有<mark>把拟合直线拖向⾃⼰</mark>的倾向，称之为⾼杠杆点</li>
<li>判断强影响点：库克距离 $D_i=\frac{\sum_{j = 0}^{n} (y_j-y_{j(i)})^2}{p ·MSE}$ ＞0.5, 度量去除某一数据点后其它样本拟合值的变化。强影响点是对统计推断产⽣较⼤影响的数据点，删除该点会导致拟合模型的实质性变化，如参数估计值、拟合值或检验值发⽣较⼤变化。<mark>库克距离是一个综合指标，结合了杠杆值和残差大小，用来评估数据点对回归系数估计的整体影响。</mark></li>
</ul>
</li>
</ul>
<hr>
<h2 id="变量选择中评价模型的指标">变量选择中评价模型的指标<a hidden class="anchor" aria-hidden="true" href="#变量选择中评价模型的指标">#</a></h2>
<ul>
<li>自由度调整复决定系数越大越好；</li>
<li>AIC 和 BIC：这两个准则都是基于似然函数，考虑了模型复杂度的惩罚。在⽐较多个模型时，AIC 和BIC 较⼩的模型被认为更优； ^grw9h5</li>
<li>$C_p$ 统计量越小越好；</li>
<li>调整 $R^2$：对 $R^2$ 进⾏调整，考虑了模型中变量的数量。在模型中添加更多变量时，即使这些变量对模型的贡献很⼩，$R^2$ 也可能会增加。调整后的 $R^2$ 提供了⼀个更为准确的衡量标准。</li>
<li>残差图分析：通过观察残差（实际值与预测值之差）的分布情况，可以评估模型是否满⾜线性回归的假设，例如残差的独⽴性、正态性和⽅差⻬性。</li>
<li>下面这几个有些许风险：选择解释变量时不应以 SSE 为标准，因为变量↑，SSE 一定↓（想象过拟合，调整 $R^2$ 就解决了这个问题），可以看看各变量系数是否显著。
<ul>
<li>均⽅误差：计算模型预测值与实际值差值的平⽅的平均值。MSE 越⼩，模型的预测准确度越⾼ 。</li>
<li>均⽅根误差：MSE 的平⽅根。RMSE 是衡量模型预测误差的常⽤标准，越⼩表示模型预测越准确。</li>
<li>平均绝对误差：计算模型预测值与实际值差值的绝对值的平均值。MAE 提供了预测误差的另⼀种衡量，对异常值的敏感度低于 MSE。</li>
<li>决定系数：衡量模型预测值的变异性占总变异性的比例，值范围从 0 到 1。$R^2$ 值越接近 1 ，表示模型解释的变异性越⼤，拟合度越好。</li>
</ul>
</li>
</ul>
<p>选择合适的评估⽅法取决于具体的研究目的和数据特性。通常，结合使⽤多种评估指标可以更全⾯地了解回归模型的性能。</p>
<p><img loading="lazy" src="https://pictest.20250303.xyz/img/202503111105261.png" alt="e0434a5a33e6b1efade0cecd0616b0f.jpg"  />
</p>
<p>❗注意弄清楚 F 检验统计量和 $R^2$ 的表达式: $F=\frac{MSR}{MSE}$, $R^2=\frac{SSR}{SST}$</p>
<p>$$
R^2=\frac{SSR}{SST}=\frac{\sum (\hat{y_i}-\bar{y_i})^2}{\sum (y_i-\bar{y})^2}=\frac{\sum (\hat{\beta_0}+\hat{\beta_1}x_i-\hat{\beta_0}-\hat{\beta_1}\bar{x})^2}{L_{yy}}=\frac{\hat{\beta_1}^2 \sum (x_i-\bar{x})^2}{L_{yy}}=\frac{\hat{\beta_1}^2L_{xx}}{L_{yy}}
$$</p>
<p>其中 $\hat{\beta_1}^2=(\frac{L_{xy}}{L_{xx}})^2$, 故 $R^2=\frac{L_{xy}^2}{L_{xx}·L_{yy}}=(\frac{L_{xy}}{\sqrt{L_{xx}L_{yy}}})^2=r^2$.</p>
<p>$$
F=\frac{MSR}{MSE}=\frac{SSR/1}{SSE/(n-2)}=\frac{(n-2)SSR}{SSE}=(n-2)\frac{SSR}{SST-SSR}=(n-2)\frac{R^2}{1-R^2}
$$</p>
<p>注意这里的自由度要根据实际情况调整。</p>
<p>$$
t=\frac{\hat{\beta_1}\sqrt{L_{xx}}}{\hat{\sigma}}\overset{分解\hat{\beta_1}}{=}\frac{r·\sqrt{L_{yy}}}{\sqrt{L_{xx}}}·\frac{\sqrt{L_{xx}}}{\hat{\sigma}}=\frac{r·\sqrt{L_{yy}}}{\sqrt{SSE/(n-2)}}\overset{L_{yy}=SST}{=}r·\sqrt{n-2}·\sqrt{\frac{SST}{SSE}}=\frac{r·\sqrt{n-2}}{\sqrt{1-r^2}}
$$</p>
<hr>
<h2 id="误差残差与偏差">误差、残差与偏差<a hidden class="anchor" aria-hidden="true" href="#误差残差与偏差">#</a></h2>
<ul>
<li>误差:观测值与真实值的偏离，如多次测量取平均值中的“测量误差”；</li>
<li>残差:观测值与模型估计值的偏离，理想情况下，如果模型是最优的，并且符合假设（如线性回归假设误差是独立同分布的），那么残差可以被视为<mark>随机噪声</mark>。但如果模型存在欠拟合、遗漏变量、异方差性等问题，<mark>残差可能不仅仅是随机噪声，而是包含了系统性误差</mark>。</li>
<li>偏差:观测值与模型估计值的偏离，排除噪声的影响，偏差是模型无法准确表达数据关系导致，比如模型过于简单，非线性的数据关系采用线性模型建模等，反映模型本身的精确度。</li>
</ul>
<p><img loading="lazy" src="https://static.geekbang.org/infoq/5cc80228c3c79.png" alt="偏差-方差-泛化误差之间的关系"  />
注：左图来自<a href="https://arxiv.org/abs/1812.11118">论文</a>，右图来自<a href="https://scott.fortmann-roe.com/docs/BiasVariance.html">文章</a></p>
<p>针对欠拟合和过拟合的处理方式如下：</p>
<ul>
<li>欠拟合：偏差过大，做特征工程、减小(弱) 正则化系数；</li>
<li>过拟合：方差过大，可增加样本、减少特征、增加(强)正则化系数；</li>
</ul>
<p>过拟合会导致方差偏大，核心原因在于模型对训练数据的依赖过强，从而导致其泛化能力下降。在偏差-方差分解（Bias-Variance Tradeoff）中：$\mathbb{E}[(\hat{y} - y)^2] = \text{Bias}^2 + \text{Variance} + \text{Noise}$</p>
<p>过拟合时，模型在训练集上的偏差几乎总是很小，而在验证集上，偏差可能不明显，但高方差会导致测试误差增大。</p>
<p>过拟合会导致方差偏大的本质原因是模型对训练数据的学习过度，使得它对新数据的预测波动性增加，从而导致测试误差的不稳定性。这也就是为什么在深度学习或机器学习任务中，我们通常需要正则化（如L1/L2正则化、Dropout）、数据增强或早停（Early Stopping）等方法来降低方差，提高泛化能力。</p>
<blockquote>
<p>残差分析中的 QQ 图：用于对残差进行正态性检验（P-P图和Q-Q图都是用于检验样本的概率分布是否服从某种理论分布。一定要严格落在对角线上吗？普通直线行不行？Ans: 行！残差近似于⼀条直线：说明残差的分布与正态分布⾮常接近，即残差基本服从正态分布）</p>
</blockquote>
<hr>
<h2 id="各种系数概念辨析">各种“系数”概念辨析<a hidden class="anchor" aria-hidden="true" href="#各种系数概念辨析">#</a></h2>
<p>决定系数（又称拟合优度、判定系数） $R^2 = \frac{SSR}{SST} = \frac{\sum_{i=1}^{n} (\hat{y}_i - \overline{y})^2}{\sum_{i=1}^{n} (y_i - \overline{y})^2}$. 它指的是回归平方和占总平方和的比重, 表示自变量对因变量随机性的解释比例, 同时也反映了自变量和因变量的线性相关性强弱。</p>
<p>分为一元和多元两个情形讨论。</p>
<h3 id="一元情形">一元情形<a hidden class="anchor" aria-hidden="true" href="#一元情形">#</a></h3>
<p>Pearson 相关系数的平方 $r^2$ = 决定系数 $R^2$ （又称拟合优度、判定系数）</p>
<h3 id="多元情形">多元情形<a hidden class="anchor" aria-hidden="true" href="#多元情形">#</a></h3>
<p>偏相关系数：在控制其他变量的影响后，两个变量之间的净相关关系。</p>
<p>复相关系数 R：因变量 Y 与多个自变量的线性组合之间的相关系数。</p>
<p>决定系数 $R^2$ =复相关系数 R 的平方。</p>
<hr>
<h2 id="区间估计--区间预测">区间估计 &amp; 区间预测<a hidden class="anchor" aria-hidden="true" href="#区间估计--区间预测">#</a></h2>
<p><img loading="lazy" src="https://pictest.20250303.xyz/img/202503102229257.png" alt="e202f85fcaebb1a95e5f0c239ac8760.jpg"  />
</p>
<hr>
<h2 id="有截距项-vs-无截距项">有截距项 Vs 无截距项<a hidden class="anchor" aria-hidden="true" href="#有截距项-vs-无截距项">#</a></h2>
<p>有截距项回归模型残差和为 0；无截距项回归模型残差和不一定为 0</p>
<p>下面讨论方差分析自由度，其中 k 为自变量个数。⚠️<mark>不同教材对 k 的定义可能不一样！</mark></p>
<ul>
<li>有截距项方差分析，实际参数为 k+1 个(截距项)，自由度: SST: n-1, SSR: k, SSE: n-k-1</li>
<li>无截距项方差分析，实际参数就是 k 个，自由度: SST: n, SSR: k, SSE: n-k</li>
</ul>
<hr>
<h2 id="在回归分析中如何处理无序变量">在回归分析中，如何处理无序变量？<a hidden class="anchor" aria-hidden="true" href="#在回归分析中如何处理无序变量">#</a></h2>
<p>分两种情况：自变量是无序变量、因变量是无序变量（Logistic 回归，在线性回归的基础上加了一个 Sigmoid 函数（非线形）映射，使得逻辑回归称为了一个优秀的分类算法）。</p>
<p>下面详细写写自变量是无序变量的情形：</p>
<p>处理无序变量，核心思想就是“编码”，参考 <a href="https://blog.csdn.net/chen695969/article/details/136141678">解决（几乎）任何机器学习问题：处理分类变量篇（上篇）</a></p>
<p>设置哑变量。哑变量：又称为虚拟变量、虚设变量或名义变量。对于有n个分类属性的自变量，通常需要选取1个分类作为参照，因此可以产生n-1个哑变量。<mark>哑变量即 One-Hot Encoding!</mark></p>
<p>当回归模型有截距项时，只能引入 m-1 个虚拟变量，否则就会陷入“虚拟变量陷阱”；当回归模型无截距项时，可以引入 m 个虚拟变量。</p>
<p><strong>One-Hot Encoding</strong>：这是最基础也是最常见的转换手段之一。它会给每个类别创建一个新的二进制列，并标记是否存在该值(0 或者 1)。然而这种方法可能会导致维度爆炸的问题，在类别过多的情况下生成大量的新特性。</p>
<hr>
<p>下面的其它 Encoding 方法先浅浅涉猎，在归纳机器学习的时候再深入了解。</p>
<ol>
<li><strong>Binary Encoding</strong>;</li>
<li><strong>BaseN Encoding</strong>;</li>
<li><strong>Target Encoding / Mean Encoding</strong>;</li>
<li><strong>Feature Hashing (Hash Trick)</strong>.</li>
</ol>
<hr>
<h2 id="写在后面---区分回归关系因果关系和相关关系">写在后面 - 区分回归关系、因果关系和相关关系<a hidden class="anchor" aria-hidden="true" href="#写在后面---区分回归关系因果关系和相关关系">#</a></h2>
<p>先说回归关系和相关关系的区别：回归关系是有方向性的，解释一个变量对另一个变量的影响，即区分因变量和自变量；而相关关系是没有方向的，变量间的地位是对等的。</p>
<p>下面着重介绍一下因果关系和相关关系的区别与联系：</p>
<p>因果关系的证明通常不是来自于单独的统计检验，而是来自于谨慎的实验设计。</p>
<blockquote>
<p>鉴别因果性最好和最科学的方法就是控制变量与盲测，例如美国FDD药品测试的随机双盲测试。</p>
</blockquote>
<p>图灵奖得主、“贝叶斯网络之父” Judea Pearl写了一本书，《为什么：关于因果关系的新科学》, 阐述了因果之梯：从低到高分别是：<strong>关联、干预、反事实推理</strong>。</p>
<p><img loading="lazy" src="https://pictest.20250303.xyz/img/202503161103199.png" alt="image.png"  />
</p>
<p>第一层级是<strong>关联（Association）</strong>，即<strong>相关关系</strong>：“事件A发生时，事件B也发生”。注意：并不能得出事件之间的影响方向，比如是不是因为事件A的发生导致了事件B的发生。</p>
<p>第二层级是<strong>干预（Intervention）</strong>，当通过干预使事件A 发生改变时，事件B是否会跟着随之改变。</p>
<p>第三层级是<strong>反事实（Counterfactual）</strong>，借由<strong>想象（Imaging）</strong>，也可以理解为“执果索因”、“以终推始”，可以想象下，如果想让事件B发生某种变化时，能否通过改变事件A来实现。</p>
<p>参考<a href="https://zhuanlan.zhihu.com/p/352630725">这篇知乎文章</a>。</p>
<ul>
<li><input disabled="" type="checkbox"> 等复试完看看这本书</li>
</ul>


    </div>

    <footer class="post-footer">
      
<nav class="paginav">
  <a class="next" href="https://20250303.xyz/posts/3.-resources-%E8%B5%84%E6%BA%90-%E6%9C%AA%E6%9D%A5/%E7%BB%9F%E8%AE%A1%E5%AD%A6-ml/%E4%B9%9D%E9%98%B3%E7%9C%9F%E7%BB%8F---%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%AF%87/">
    <span class="title"> »</span>
    <br>
    <span>九阳真经 - 假设检验篇</span>
  </a>
</nav>

    </footer>
  </div><style>
    .comments_details summary::marker {
        font-size: 20px;
        content: '👉展开评论';
        color: var(--content);
    }
    .comments_details[open] summary::marker{
        font-size: 20px;
        content: '👇关闭评论';
        color: var(--content);
    }
</style>


<div>
    <details class="comments_details">
        <summary style="cursor: pointer; margin: 50px 0 20px 0;width: 130px;">
            <span style="font-size: 20px;color: var(--content);">...</span>
        </summary>
        <div id="tcomment"></div>
    </details>
    <script src=" https://cdn.jsdelivr.net/npm/twikoo@1.6.41/dist/twikoo.min.js 1.6.41/twikoo.all.min.js">
    
    </script>
    <script>
        twikoo.init({
            envId: "https://twikoo.20250303.xyz",
            el: "#tcomment",
            lang: 'zh-CN',
            region:  null ,
            
        })
    </script>
</div>
</article>
    </main>
    
<footer class="footer">
    <span>
        Copyright
        &copy;
        2024-2025
        <a href="https://20250303.xyz/" style="color:#939393;">Lovegood&#39;s Blog</a>
        All Rights Reserved.
    </span>
    
    <div class="busuanzi-footer">
        <span id="busuanzi_container_site_pv">
            本站总访问量<span id="busuanzi_value_site_pv"></span>次
        </span>
        <span id="busuanzi_container_site_uv">
            本站访客数<span id="busuanzi_value_site_uv"></span>人次
        </span>
        </div>
    
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <span class="topInner">
        <svg class="topSvg" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
            <path d="M12 6H0l6-6z"/>
        </svg>
        <span id="read_progress"></span>
    </span>
</a>

<script>
    document.addEventListener('scroll', function (e) {
        const readProgress = document.getElementById("read_progress");
        const scrollHeight = document.documentElement.scrollHeight;
        const clientHeight = document.documentElement.clientHeight;
        const scrollTop = document.documentElement.scrollTop || document.body.scrollTop;
        readProgress.innerText = ((scrollTop / (scrollHeight - clientHeight)).toFixed(2) * 100).toFixed(0);
    })
</script>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });
</script>
<script>
    let mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 200 || document.documentElement.scrollTop > 200) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };
</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        (function() {
            document.cookie = "change-themes" + "="+ escape ("false");
        })()

        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    });
</script>

<script>
    document.body.addEventListener('copy', function (e) {
        if (window.getSelection().toString() && window.getSelection().toString().length > 50) {
            let clipboardData = e.clipboardData || window.clipboardData;
            if (clipboardData) {
                e.preventDefault();
                let htmlData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"Lovegood's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                let textData = window.getSelection().toString() +
                    '\r\n\n————————————————\r\n' +
                    '版权声明：本文为「'+"Lovegood's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                clipboardData.setData('text/html', htmlData);
                clipboardData.setData('text/plain', textData);
            }
        }
    });
</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;
        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerText = 'copy';

        function copyingDone() {
            copybutton.innerText = 'copied!';
            setTimeout(() => {
                copybutton.innerText = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                let text = codeblock.textContent +
                    '\r\n————————————————\r\n' +
                    '版权声明：本文为「'+"Lovegood's Blog"+'」的原创文章，遵循CC 4.0 BY-SA版权协议，转载请附上原文出处链接及本声明。' +
                '\r\n原文链接：' + location.href;
                navigator.clipboard.writeText(text);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) {}
            selection.removeRange(range);
        });

        let language = codeblock.className.replaceAll("language-", "")
        let macTool = document.createElement("div")
        let macTool1 = document.createElement("div")
        let macTool2 = document.createElement("div")
        let macTool3 = document.createElement("div")
        let languageType = document.createElement("div")
        languageType.innerText = language
        macTool.setAttribute('class', 'mac-tool')
        macTool1.setAttribute('class', 'mac bb1')
        macTool2.setAttribute('class', 'mac bb2')
        macTool3.setAttribute('class', 'mac bb3')
        languageType.setAttribute('class', 'language-type')
        macTool.appendChild(macTool1)
        macTool.appendChild(macTool2)
        macTool.appendChild(macTool3)
        macTool.appendChild(languageType)

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
            container.appendChild(macTool)
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
            container.appendChild(macTool)
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
            
        }
    });
</script></body>







</html>
